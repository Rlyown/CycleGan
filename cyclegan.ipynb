{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import Lib"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tensorflow.keras.layers import InputSpec, Layer\nfrom tensorflow.keras import Model\ntry:\n    from kaggle_datasets import KaggleDatasets\n    REMOTE_FLAG = True\nexcept:\n    print(\"Load Local Dataset\")\n    REMOTE_FLAG = False\n    ","execution_count":94,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Setup TPU"},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n\nAUTO = tf.data.experimental.AUTOTUNE\nprint(tf.__version__)","execution_count":95,"outputs":[{"output_type":"stream","text":"Number of replicas: 1\n2.2.0\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = [256, 256]\ndef decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = (tf.cast(image, tf.float32) / 127.5) - 1\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image\n\ndef read_tfrecord(example):\n    tfrecord_format = {\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example['image'])\n    return image\n\ndef load_dataset(filenames):\n    dataset = tf.data.TFRecordDataset(filenames)\n    # print(dataset)\n    dataset = dataset.map(read_tfrecord, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    return dataset\n\n\ndef get_dataset(filenames, augment=None, repeat=True, shuffle=True, batch_size=1):\n    dataset = load_dataset(filenames)\n\n    if augment:\n        dataset = dataset.map(augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    if repeat:\n        dataset = dataset.repeat(count=1)\n\n    dataset = dataset.concatenate(load_dataset(filenames))\n\n    if shuffle:\n        dataset = dataset.shuffle(1000)\n\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n\n    return dataset\n\ndef data_augment_2(image):\n    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n\n    # Apply jitter\n    if p_crop > .5:\n        image = tf.image.resize(image, [286, 286])\n        image = tf.image.random_crop(image, size=[256, 256, 3])\n        if p_crop > .9:\n            image = tf.image.resize(image, [300, 300])\n            image = tf.image.random_crop(image, size=[256, 256, 3])\n\n    # Random rotation\n    if p_rotate > .9:\n        image = tf.image.rot90(image, k=3)  # rotate 270º\n    elif p_rotate > .7:\n        image = tf.image.rot90(image, k=2)  # rotate 180º\n    elif p_rotate > .5:\n        image = tf.image.rot90(image, k=1)  # rotate 90º\n\n    # Random mirroring\n    if p_spatial > .6:\n        image = tf.image.random_flip_left_right(image)\n        image = tf.image.random_flip_up_down(image)\n        if p_spatial > .9:\n            image = tf.image.transpose(image)\n\n    return image","execution_count":96,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if REMOTE_FLAG:\n    GCS_PATH = KaggleDatasets().get_gcs_path('gan-getting-started')\nelse:\n    GCS_PATH = './gan-getting-started'\nMONET_FILENAMES = tf.io.gfile.glob(str(GCS_PATH + '/monet_tfrec/*.tfrec'))\nPHOTO_FILENAMES = tf.io.gfile.glob(str(GCS_PATH + '/photo_tfrec/*.tfrec'))\nmonet_ds = get_dataset(MONET_FILENAMES, augment=data_augment_2, batch_size=1)\nphoto_ds = get_dataset(PHOTO_FILENAMES, augment=data_augment_2, batch_size=1)","execution_count":97,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    loss_object = keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n\n    # Define loss functions\n    def discriminator_loss(disc_real_output, disc_generated_output):\n        # compare the real image with a matrix of 1. (All Ok)\n        real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n\n        # compare the fake image with a matrix of 0 (All Fake)\n        generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n\n        total_disc_loss = (real_loss + generated_loss) / 2\n\n        return total_disc_loss\n\n\n    def generator_adversarial_loss(generated):\n        return loss_object(tf.ones_like(generated), generated)\n\n\n    def generator_calc_cycle_loss(real_image, cycled_image, param_lambda):\n        loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n        return param_lambda * loss1\n\n\n    def generator_identity_loss(real_image, same_image, param_lambda):\n        loss = tf.reduce_mean(tf.abs(real_image - same_image))\n        return param_lambda * 0.5 * loss","execution_count":98,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# optimizer of each model"},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    generator_monet_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n    generator_photo_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n    discriminator_monet_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n    discriminator_photo_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)","execution_count":99,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CycleGan(keras.Model):\n    def __init__(\n            self,\n            generator_monet,\n            generator_photo,\n            discriminator_monet,\n            discriminator_photo,\n            lambda_cycle=10,\n            lambda_identity=10\n    ):\n        super(CycleGan, self).__init__()\n        self.generator_monet = generator_monet\n        self.generator_photo = generator_photo\n        self.discriminator_monet = discriminator_monet\n        self.discriminator_photo = discriminator_photo\n        self.lambda_cycle = lambda_cycle\n        self.lambda_identity = lambda_identity\n\n    def compile(\n            self,\n            generator_monet_optimizer,\n            generator_photo_optimizer,\n            discriminator_monet_optimizer,\n            discriminator_photo_optimizer,\n            discriminator_loss,\n            generator_adversarial_loss,\n            generator_calc_cycle_loss,\n            generator_identity_loss\n    ):\n        super(CycleGan, self).compile()\n        self.generator_monet_optimizer = generator_monet_optimizer\n        self.generator_photo_optimizer = generator_photo_optimizer\n        self.discriminator_monet_optimizer = discriminator_monet_optimizer\n        self.discriminator_photo_optimizer = discriminator_photo_optimizer\n        self.discriminator_loss = discriminator_loss\n        self.generator_adversarial_loss = generator_adversarial_loss\n        self.generator_calc_cycle_loss = generator_calc_cycle_loss\n        self.generator_identity_loss = generator_identity_loss\n\n    def train_step(self, batch_data):\n        monet, photo = batch_data\n\n        with tf.GradientTape(persistent=True) as tape:\n            # photo to monet back to photo\n            gen_output_monet_fake = self.generator_monet(photo, training=False)\n            gen_output_photo_cycle = self.generator_photo(gen_output_monet_fake, training=False)\n\n            # monet to photo back to monet\n            gen_output_photo_fake = self.generator_photo(monet, training=False)\n            gen_output_monet_cycle = self.generator_monet(gen_output_photo_fake, training=False)\n\n            # generating itself\n            gen_output_monet_same = self.generator_monet(monet, training=False)\n            gen_output_photo_same = self.generator_photo(photo, training=False)\n\n            # discriminator used to check, inputing real images\n            disc_out_monet_real = self.discriminator_monet(monet, training=False)\n            disc_out_photo_real = self.discriminator_photo(photo, training=False)\n\n            # discriminator used to check, inputing fake images\n            disc_out_monet_fake = self.discriminator_monet(gen_output_monet_fake, training=False)\n            disc_out_photo_fake = self.discriminator_photo(gen_output_photo_fake, training=False)\n\n\n\n            # evaluates generator loss\n            gen_monet_adversarial_loss = self.generator_adversarial_loss(disc_out_monet_fake)\n            gen_photo_adversarial_loss = self.generator_adversarial_loss(disc_out_photo_fake)\n\n            total_cycle_loss = (self.generator_calc_cycle_loss(monet, gen_output_monet_cycle, self.lambda_cycle)\n                                + self.generator_calc_cycle_loss(photo, gen_output_photo_cycle, self.lambda_cycle))\n\n            gen_monet_identity_loss = self.generator_identity_loss(monet, gen_output_monet_same, self.lambda_identity)\n            gen_photo_identity_loss = self.generator_identity_loss(photo, gen_output_photo_same, self.lambda_identity)\n\n            # Total generator loss = adversarial loss + cycle loss + identity loss\n            total_gen_monet_loss = (gen_monet_adversarial_loss + total_cycle_loss + gen_monet_identity_loss)\n            total_gen_photo_loss = (gen_photo_adversarial_loss + total_cycle_loss + gen_photo_identity_loss)\n\n            # evaluates discriminator loss\n            disc_monet_loss = self.discriminator_loss(disc_out_monet_real, disc_out_monet_fake)\n            disc_photo_loss = self.discriminator_loss(disc_out_photo_real, disc_out_photo_fake)\n\n\n        # Calculate the gradients for generator and discriminator\n        gen_monet_gradients = tape.gradient(total_gen_monet_loss,\n                                            self.generator_monet.trainable_variables)\n        gen_photo_gradients = tape.gradient(total_gen_photo_loss,\n                                            self.generator_photo.trainable_variables)\n\n        disc_monet_gradients = tape.gradient(disc_monet_loss,\n                                             self.discriminator_monet.trainable_variables)\n        disc_photo_gradients = tape.gradient(disc_photo_loss,\n                                             self.discriminator_photo.trainable_variables)\n\n        # Apply the gradients to the optimizer\n        self.generator_monet_optimizer.apply_gradients(zip(gen_monet_gradients,\n                                                           self.generator_monet.trainable_variables))\n        self.generator_photo_optimizer.apply_gradients(zip(gen_photo_gradients,\n                                                           self.generator_photo.trainable_variables))\n\n        self.discriminator_monet_optimizer.apply_gradients(zip(disc_monet_gradients,\n                                                               self.discriminator_monet.trainable_variables))\n        self.discriminator_photo_optimizer.apply_gradients(zip(disc_photo_gradients,\n                                                               self.discriminator_photo.trainable_variables))\n\n        return {\n            \"total_gen_monet_loss\": total_gen_monet_loss,\n            \"total_gen_photo_loss\": total_gen_photo_loss,\n            \"disc_monet_loss\": disc_monet_loss,\n            \"disc_photo_loss\": disc_photo_loss\n        }","execution_count":100,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Down/Up sample"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Build the generator preparation\nwith strategy.scope():\n    def downsample(filters, size, apply_instancenorm=True):\n        initializer = tf.random_normal_initializer(0., 0.02)\n\n        result = keras.Sequential()\n        result.add(layers.Conv2D(filters, size, strides=2, padding='same',\n                                 kernel_initializer=initializer, use_bias=not apply_instancenorm ))# when applying Normalization you already have the bias implicit\n        result.add(layers.LeakyReLU())\n        return result\n\n    def upsample(filters, size, apply_dropout=False):\n        initializer = tf.random_normal_initializer(0., 0.02)\n\n        result = keras.Sequential()\n        result.add(layers.Conv2DTranspose(filters, size, strides=2,\n                                          padding='same',\n                                          kernel_initializer=initializer,\n                                          use_bias=False))\n        if apply_dropout:\n            result.add(layers.Dropout(0.5))\n\n        result.add(layers.ReLU())\n        return result","execution_count":101,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Resnet Block"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ReflectionPadding2D(Layer):\n    def __init__(self, padding=(1, 1), **kwargs):\n        self.padding = tuple(padding)\n        self.input_spec = [InputSpec(ndim=4)]\n        super(ReflectionPadding2D, self).__init__(**kwargs)\n\n    def compute_output_shape(self, s):\n        if s[1] == None:\n            return (None, None, None, s[3])\n        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n\n    def call(self, x, mask=None):\n        w_pad, h_pad = self.padding\n        return tf.pad(x, [[0, 0], [h_pad, h_pad], [w_pad, w_pad], [0, 0]], 'REFLECT')\n\n    def get_config(self):\n        config = super(ReflectionPadding2D, self).get_config()\n        print(config)\n        return config","execution_count":102,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ResnetBlock(Model):\n\n    def __init__(self, filters, strides=1):\n        super(ResnetBlock, self).__init__()\n        self.filters = filters\n        self.strides = strides\n\n        self.p1 = ReflectionPadding2D()\n        self.c1 = keras.layers.Conv2D(filters, (3, 3), strides=strides, padding='valid', use_bias=False)\n        self.b1 = tfa.layers.InstanceNormalization()\n        self.a1 = keras.layers.Activation('relu')\n\n        self.p2 = ReflectionPadding2D()\n        self.c2 = keras.layers.Conv2D(filters, (3, 3), strides=strides, padding='valid', use_bias=False)\n        self.b2 = tfa.layers.InstanceNormalization()\n\n    def call(self, inputs):\n        residual = inputs  # residual等于输入值本身，即residual=x\n        # 将输入通过卷积、BN层、激活层，计算F(x)\n        x = self.p1(inputs)\n        x = self.c1(x)\n        x = self.b1(x)\n        x = self.a1(x)\n\n        x = self.p2(x)\n        x = self.c2(x)\n        y = self.b2(x) + residual\n        return y\n","execution_count":103,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Generator(Model):\n\n    def __init__(self):  # block_list表示每个block有几个卷积层\n        \n        super(Generator, self).__init__()\n        self.num_blocks = 9\n        \n        self.p1 = ReflectionPadding2D((3, 3))\n        self.c1 = keras.layers.Conv2D(64, (7, 7), strides=1, padding='valid', use_bias=False)\n        self.b1 = tfa.layers.InstanceNormalization()\n        self.a1 = keras.layers.Activation('relu')\n        \n        # Two down sampling layers\n        self.c2 = keras.layers.Conv2D(128, (3, 3), strides=2, padding='same', use_bias=False)\n        self.b2 = tfa.layers.InstanceNormalization()\n        self.a2 = keras.layers.Activation('relu')\n        \n        self.c3 = keras.layers.Conv2D(256, (3, 3), strides=2, padding='same', use_bias=False)\n        self.b3 = tfa.layers.InstanceNormalization()\n        self.a3 = keras.layers.Activation('relu')\n        \n        # Calc Blocks\n        self.blocks = keras.models.Sequential()\n        # 构建ResNet网络结构\n        for block_id in range(self.num_blocks):  # 第几个resnet block\n            block = ResnetBlock(256)\n            self.blocks.add(block)  # 将构建好的block加入resnet\n            \n        # Two up Sampling layers\n        self.t4 = keras.layers.Conv2DTranspose(128, (3, 3), strides=2, padding='same', output_padding=1)\n        self.b4 = tfa.layers.InstanceNormalization()\n        self.a4 = keras.layers.Activation('relu')\n        \n        self.t5 = keras.layers.Conv2DTranspose(64, (3, 3), strides=2, padding='same', output_padding=1)\n        self.b5 = tfa.layers.InstanceNormalization()\n        self.a5 = keras.layers.Activation('relu')\n                \n        self.p6 = ReflectionPadding2D((3, 3))\n        self.c6 = keras.layers.Conv2D(3, (7, 7), strides=1, padding='valid', use_bias=False)\n        self.a6 = keras.layers.Activation('tanh')\n        \n\n    def call(self, inputs):\n        x = self.p1(inputs)\n        x = self.c1(x)\n        x = self.b1(x)\n        x = self.a1(x)\n        \n        x = self.c2(x)\n        x = self.b2(x)\n        x = self.a2(x)\n        \n        x = self.c3(x)\n        x = self.b3(x)\n        x = self.a3(x)\n        \n        x = self.blocks(x)\n        \n        x = self.t4(x)\n        x = self.b4(x)\n        x = self.a4(x)\n        \n        x = self.t5(x)\n        x = self.b5(x)\n        x = self.a5(x)\n        \n        x = self.p6(x)\n        x = self.c6(x)\n        y = self.a6(x)\n        return y","execution_count":104,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Discriminator"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build the discriminator\ndef Discriminator():\n    initializer = tf.random_normal_initializer(0., 0.02)\n\n    inp = layers.Input(shape=[256, 256, 3], name='input_image')\n\n    down1 = downsample(64, 4, False)(inp) # (bs, 128, 128, 64)\n    down2 = downsample(128, 4)(down1) # (bs, 64, 64, 128)\n    down3 = downsample(256, 4)(down2) # (bs, 32, 32, 256)\n\n    zero_pad1 = layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n    conv = layers.Conv2D(512, 4, strides=1,\n                         kernel_initializer=initializer,\n                         use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n\n    leaky_relu = layers.LeakyReLU()(conv)\n\n    zero_pad2 = layers.ZeroPadding2D()(leaky_relu)  # (bs, 33, 33, 512)\n\n    last = layers.Conv2D(1,\n                         kernel_size = 4,\n                         strides=1,\n                         kernel_initializer=initializer)(zero_pad2)  # (bs, 30, 30, 1)\n\n    return tf.keras.Model(inputs=inp, outputs=last)","execution_count":106,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    #Create Generator and Discriminator\n    generator_monet = Generator() # transforms photos to Monet-esque paintings\n    generator_photo = Generator() # transforms Monet paintings to be more like photos\n    discriminator_monet = Discriminator() # differentiates real Monet paintings and generated Monet paintings\n    discriminator_photo = Discriminator() # differentiates real photos and generated photos","execution_count":107,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    cycle_gan_model = CycleGan(\n        generator_monet, generator_photo, discriminator_monet, discriminator_photo\n    )\n\n    cycle_gan_model.compile(\n            generator_monet_optimizer = generator_monet_optimizer,\n            generator_photo_optimizer = generator_photo_optimizer,\n            discriminator_monet_optimizer = discriminator_monet_optimizer,\n            discriminator_photo_optimizer = discriminator_photo_optimizer,\n            discriminator_loss = discriminator_loss,\n            generator_adversarial_loss = generator_adversarial_loss,\n            generator_calc_cycle_loss = generator_calc_cycle_loss,\n            generator_identity_loss = generator_identity_loss\n        )","execution_count":108,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cycle_gan_model.fit(\n    tf.data.Dataset.zip((monet_ds, photo_ds)),\n    epochs=1\n)","execution_count":109,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"in user code:\n\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    <ipython-input-100-eeb6809971eb>:45 train_step  *\n        gen_output_monet_fake = self.generator_monet(photo, training=False)\n    <ipython-input-104-be3e5d3e657f>:68 call  *\n        x = self.b6(x)\n\n    AttributeError: 'Generator' object has no attribute 'b6'\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-109-655949fc0229>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m cycle_gan_model.fit(\n\u001b[1;32m      2\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonet_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphoto_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    <ipython-input-100-eeb6809971eb>:45 train_step  *\n        gen_output_monet_fake = self.generator_monet(photo, training=False)\n    <ipython-input-104-be3e5d3e657f>:68 call  *\n        x = self.b6(x)\n\n    AttributeError: 'Generator' object has no attribute 'b6'\n"]}]},{"metadata":{},"cell_type":"markdown","source":"# Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot\n_, ax = plt.subplots(5, 2, figsize=(12, 12))\nfor i, img in enumerate(photo_ds.take(5)):\n    prediction = generator_monet(img, training=False)[0].numpy()\n    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n    img = (img[0] * 127.5 + 127.5).numpy().astype(np.uint8)\n\n    ax[i, 0].imshow(img)\n    ax[i, 1].imshow(prediction)\n    ax[i, 0].set_title(\"Input Photo\")\n    ax[i, 1].set_title(\"Monet-esque\")\n    ax[i, 0].axis(\"off\")\n    ax[i, 1].axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SAVE"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import PIL\n# ! mkdir ../images\n# i = 1\n# for img in photo_ds:\n#     prediction = monet_generator(img, training=False)[0].numpy()\n#     prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n#     im = PIL.Image.fromarray(prediction)\n#     im.save(\"../images/\" + str(i) + \".jpg\")\n#     i += 1\n    \n# import shutil\n# shutil.make_archive(\"/kaggle/working/images\", 'zip', \"/kaggle/images\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}